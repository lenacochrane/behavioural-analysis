{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "# widely used for a variety of image and video analysis\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/cochral/Desktop/SLAEP/EXTRACT/FOOD-2%/DAY4/N10/2024-04-30_14-31-44_td5.000_2024-04-30_14-31-44_td5.analysis.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track</th>\n",
       "      <th>frame_idx</th>\n",
       "      <th>instance.score</th>\n",
       "      <th>head.x</th>\n",
       "      <th>head.y</th>\n",
       "      <th>head.score</th>\n",
       "      <th>body.x</th>\n",
       "      <th>body.y</th>\n",
       "      <th>body.score</th>\n",
       "      <th>tail.x</th>\n",
       "      <th>tail.y</th>\n",
       "      <th>tail.score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>track_0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.997690</td>\n",
       "      <td>544.022156</td>\n",
       "      <td>600.235962</td>\n",
       "      <td>0.828238</td>\n",
       "      <td>536.157776</td>\n",
       "      <td>619.900879</td>\n",
       "      <td>0.961164</td>\n",
       "      <td>543.939880</td>\n",
       "      <td>631.457947</td>\n",
       "      <td>0.862113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>track_1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.939825</td>\n",
       "      <td>872.281250</td>\n",
       "      <td>645.013977</td>\n",
       "      <td>0.916719</td>\n",
       "      <td>852.358521</td>\n",
       "      <td>656.507385</td>\n",
       "      <td>1.013684</td>\n",
       "      <td>829.165405</td>\n",
       "      <td>664.990845</td>\n",
       "      <td>0.900837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>track_2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.961724</td>\n",
       "      <td>792.746399</td>\n",
       "      <td>648.283081</td>\n",
       "      <td>1.076889</td>\n",
       "      <td>796.195068</td>\n",
       "      <td>672.015564</td>\n",
       "      <td>0.967432</td>\n",
       "      <td>791.867310</td>\n",
       "      <td>687.873657</td>\n",
       "      <td>0.965457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>track_3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.926129</td>\n",
       "      <td>597.037476</td>\n",
       "      <td>668.631592</td>\n",
       "      <td>0.996625</td>\n",
       "      <td>604.342041</td>\n",
       "      <td>688.353699</td>\n",
       "      <td>1.002884</td>\n",
       "      <td>609.160400</td>\n",
       "      <td>700.735291</td>\n",
       "      <td>0.926293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>track_4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.971796</td>\n",
       "      <td>620.490417</td>\n",
       "      <td>700.677551</td>\n",
       "      <td>0.938576</td>\n",
       "      <td>640.178040</td>\n",
       "      <td>696.447510</td>\n",
       "      <td>1.000313</td>\n",
       "      <td>652.363892</td>\n",
       "      <td>688.302368</td>\n",
       "      <td>0.852670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57141</th>\n",
       "      <td>track_4</td>\n",
       "      <td>6000</td>\n",
       "      <td>1.004286</td>\n",
       "      <td>651.508362</td>\n",
       "      <td>852.711609</td>\n",
       "      <td>0.917185</td>\n",
       "      <td>635.680542</td>\n",
       "      <td>852.879761</td>\n",
       "      <td>0.955591</td>\n",
       "      <td>619.563110</td>\n",
       "      <td>841.391296</td>\n",
       "      <td>1.017871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57142</th>\n",
       "      <td>track_6</td>\n",
       "      <td>6000</td>\n",
       "      <td>0.949814</td>\n",
       "      <td>492.543610</td>\n",
       "      <td>440.291931</td>\n",
       "      <td>0.863538</td>\n",
       "      <td>488.281616</td>\n",
       "      <td>456.338562</td>\n",
       "      <td>1.005066</td>\n",
       "      <td>480.230743</td>\n",
       "      <td>468.976379</td>\n",
       "      <td>0.979406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57143</th>\n",
       "      <td>track_7</td>\n",
       "      <td>6000</td>\n",
       "      <td>1.000900</td>\n",
       "      <td>889.316895</td>\n",
       "      <td>723.603027</td>\n",
       "      <td>0.988736</td>\n",
       "      <td>912.543091</td>\n",
       "      <td>723.771851</td>\n",
       "      <td>1.002910</td>\n",
       "      <td>928.344910</td>\n",
       "      <td>723.480530</td>\n",
       "      <td>0.971155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57144</th>\n",
       "      <td>track_8</td>\n",
       "      <td>6000</td>\n",
       "      <td>0.967064</td>\n",
       "      <td>628.128784</td>\n",
       "      <td>475.767029</td>\n",
       "      <td>0.900316</td>\n",
       "      <td>628.284546</td>\n",
       "      <td>456.106537</td>\n",
       "      <td>1.011823</td>\n",
       "      <td>620.991821</td>\n",
       "      <td>436.747589</td>\n",
       "      <td>1.016621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57145</th>\n",
       "      <td>track_9</td>\n",
       "      <td>6000</td>\n",
       "      <td>0.983835</td>\n",
       "      <td>1068.289673</td>\n",
       "      <td>719.529236</td>\n",
       "      <td>0.996206</td>\n",
       "      <td>1084.120605</td>\n",
       "      <td>707.756592</td>\n",
       "      <td>0.999117</td>\n",
       "      <td>1092.577881</td>\n",
       "      <td>691.805847</td>\n",
       "      <td>1.027971</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>57146 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         track  frame_idx  instance.score       head.x      head.y  \\\n",
       "0      track_0          0        0.997690   544.022156  600.235962   \n",
       "1      track_1          0        0.939825   872.281250  645.013977   \n",
       "2      track_2          0        0.961724   792.746399  648.283081   \n",
       "3      track_3          0        0.926129   597.037476  668.631592   \n",
       "4      track_4          0        0.971796   620.490417  700.677551   \n",
       "...        ...        ...             ...          ...         ...   \n",
       "57141  track_4       6000        1.004286   651.508362  852.711609   \n",
       "57142  track_6       6000        0.949814   492.543610  440.291931   \n",
       "57143  track_7       6000        1.000900   889.316895  723.603027   \n",
       "57144  track_8       6000        0.967064   628.128784  475.767029   \n",
       "57145  track_9       6000        0.983835  1068.289673  719.529236   \n",
       "\n",
       "       head.score       body.x      body.y  body.score       tail.x  \\\n",
       "0        0.828238   536.157776  619.900879    0.961164   543.939880   \n",
       "1        0.916719   852.358521  656.507385    1.013684   829.165405   \n",
       "2        1.076889   796.195068  672.015564    0.967432   791.867310   \n",
       "3        0.996625   604.342041  688.353699    1.002884   609.160400   \n",
       "4        0.938576   640.178040  696.447510    1.000313   652.363892   \n",
       "...           ...          ...         ...         ...          ...   \n",
       "57141    0.917185   635.680542  852.879761    0.955591   619.563110   \n",
       "57142    0.863538   488.281616  456.338562    1.005066   480.230743   \n",
       "57143    0.988736   912.543091  723.771851    1.002910   928.344910   \n",
       "57144    0.900316   628.284546  456.106537    1.011823   620.991821   \n",
       "57145    0.996206  1084.120605  707.756592    0.999117  1092.577881   \n",
       "\n",
       "           tail.y  tail.score  \n",
       "0      631.457947    0.862113  \n",
       "1      664.990845    0.900837  \n",
       "2      687.873657    0.965457  \n",
       "3      700.735291    0.926293  \n",
       "4      688.302368    0.852670  \n",
       "...           ...         ...  \n",
       "57141  841.391296    1.017871  \n",
       "57142  468.976379    0.979406  \n",
       "57143  723.480530    0.971155  \n",
       "57144  436.747589    1.016621  \n",
       "57145  691.805847    1.027971  \n",
       "\n",
       "[57146 rows x 12 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMAGE OF TRACKS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot convert float NaN to integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 34\u001b[0m\n\u001b[1;32m     31\u001b[0m prev_frame, curr_frame \u001b[38;5;241m=\u001b[39m track_df\u001b[38;5;241m.\u001b[39miloc[i\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], track_df\u001b[38;5;241m.\u001b[39miloc[i]\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Draw lines between the corresponding head, body, and tail points\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m head_prev, head_curr \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mint\u001b[39m(prev_frame[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhead.x\u001b[39m\u001b[38;5;124m'\u001b[39m]), \u001b[38;5;28mint\u001b[39m(prev_frame[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhead.y\u001b[39m\u001b[38;5;124m'\u001b[39m])), (\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcurr_frame\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhead.x\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mint\u001b[39m(curr_frame[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhead.y\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n\u001b[1;32m     35\u001b[0m body_prev, body_curr \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mint\u001b[39m(prev_frame[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbody.x\u001b[39m\u001b[38;5;124m'\u001b[39m]), \u001b[38;5;28mint\u001b[39m(prev_frame[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbody.y\u001b[39m\u001b[38;5;124m'\u001b[39m])), (\u001b[38;5;28mint\u001b[39m(curr_frame[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbody.x\u001b[39m\u001b[38;5;124m'\u001b[39m]), \u001b[38;5;28mint\u001b[39m(curr_frame[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbody.y\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n\u001b[1;32m     36\u001b[0m tail_prev, tail_curr \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mint\u001b[39m(prev_frame[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtail.x\u001b[39m\u001b[38;5;124m'\u001b[39m]), \u001b[38;5;28mint\u001b[39m(prev_frame[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtail.y\u001b[39m\u001b[38;5;124m'\u001b[39m])), (\u001b[38;5;28mint\u001b[39m(curr_frame[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtail.x\u001b[39m\u001b[38;5;124m'\u001b[39m]), \u001b[38;5;28mint\u001b[39m(curr_frame[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtail.y\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n",
      "\u001b[0;31mValueError\u001b[0m: cannot convert float NaN to integer"
     ]
    }
   ],
   "source": [
    "# Set the image size\n",
    "image_size = 1400\n",
    "# np.zeros creates a new array filled with zeros\n",
    "# creates a 1400x1400 pixel image with 3 color channels (RGB)\n",
    "tracks_image = np.zeros((image_size, image_size, 3), dtype=np.uint8)\n",
    "\n",
    "# ensure sorted by frame index\n",
    "df = df.sort_values('frame_idx')\n",
    "\n",
    "# Drop rows where any of the specified columns contain NaN\n",
    "# df = df.dropna(subset=['head.x', 'head.y', 'body.x', 'body.y', 'tail.x', 'tail.y'])\n",
    "# this does not maintain integrity of timeline \n",
    "\n",
    "# Draw the tracks for each unique track ID\n",
    "for track in df['track'].unique():\n",
    "\n",
    "    # ensure that the track is unique and referring back to the for loop track \n",
    "    track_df = df[df['track'] == track]\n",
    "\n",
    "\n",
    "    # Iterate through the track data and draw lines between consecutive points\n",
    "       # the use of range(len()) will create a sequence of numbers - how to loop over the index \n",
    "       # the for loop will run from the second element (index 1) to the last element in the dataframe\n",
    "       # the reason for starting at index 1 is lines will be drawn by comparing the coordinate with its predecessor to draw a line between them\n",
    "\n",
    "    for i in range(1, len(track_df)):\n",
    "        # Get the previous and current frame data\n",
    "          # define the current and previous index \n",
    "          # will be used to compare the two rows and draw appropriate lines \n",
    "          # iloc = integer index-based -  have to specify rows and columns by their integer index (loc = specify name)\n",
    "        prev_frame, curr_frame = track_df.iloc[i-1], track_df.iloc[i]\n",
    "\n",
    "        # Draw lines between the corresponding head, body, and tail points\n",
    "        head_prev, head_curr = (int(prev_frame['head.x']), int(prev_frame['head.y'])), (int(curr_frame['head.x']), int(curr_frame['head.y']))\n",
    "        body_prev, body_curr = (int(prev_frame['body.x']), int(prev_frame['body.y'])), (int(curr_frame['body.x']), int(curr_frame['body.y']))\n",
    "        tail_prev, tail_curr = (int(prev_frame['tail.x']), int(prev_frame['tail.y'])), (int(curr_frame['tail.x']), int(curr_frame['tail.y']))\n",
    "\n",
    "        cv2.line(tracks_image, head_prev, head_curr, color=(0, 0, 255), thickness=2)\n",
    "        cv2.line(tracks_image, body_prev, body_curr, color=(0, 255, 0), thickness=2)\n",
    "        cv2.line(tracks_image, tail_prev, tail_curr, color=(255, 0, 0), thickness=2)\n",
    "\n",
    "# Save the image\n",
    "cv2.imwrite('tracks_image.png', tracks_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 28\u001b[0m\n\u001b[1;32m     25\u001b[0m track_df \u001b[38;5;241m=\u001b[39m df[df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrack\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m track]\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Loop through the color palette and assign the track a new color \u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m color \u001b[38;5;241m=\u001b[39m \u001b[43mcolors\u001b[49m\u001b[43m[\u001b[49m\u001b[43mind\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Iterate through the track data and draw lines between consecutive points\u001b[39;00m\n\u001b[1;32m     31\u001b[0m    \u001b[38;5;66;03m# the use of range(len()) will create a sequence of numbers - how to loop over the index \u001b[39;00m\n\u001b[1;32m     32\u001b[0m    \u001b[38;5;66;03m# the for loop will run from the second element (index 1) to the last element in the dataframe\u001b[39;00m\n\u001b[1;32m     33\u001b[0m    \u001b[38;5;66;03m# the reason for starting at index 1 is lines will be drawn by comparing the coordinate with its predecessor to draw a line between them\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(track_df)):\n\u001b[1;32m     35\u001b[0m     \n\u001b[1;32m     36\u001b[0m     \u001b[38;5;66;03m# Get the previous and current frame data\u001b[39;00m\n\u001b[1;32m     37\u001b[0m       \u001b[38;5;66;03m# define the current and previous index \u001b[39;00m\n\u001b[1;32m     38\u001b[0m       \u001b[38;5;66;03m# will be used to compare the two rows and draw appropriate lines \u001b[39;00m\n\u001b[1;32m     39\u001b[0m       \u001b[38;5;66;03m# iloc = integer index-based -  have to specify rows and columns by their integer index (loc = specify name)\u001b[39;00m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# Set the image size\n",
    "image_size = 1400\n",
    "# np.zeros creates a new array filled with zeros\n",
    "# creates a 1400x1400 pixel image with 3 color channels (RGB)\n",
    "tracks_image = np.zeros((image_size, image_size, 3), dtype=np.uint8)\n",
    "\n",
    "# ensure sorted by frame index\n",
    "df = df.sort_values('frame_idx')\n",
    "\n",
    "# Define a list of 10 colors for the tracks\n",
    "def generate_random_color():\n",
    "    return (random.randint(0, 255), random.randint(0, 255), random.randint(0, 255))\n",
    "\n",
    "\n",
    "\n",
    "# Create a dictionary to hold colors for each track\n",
    "track_colors = {}\n",
    "\n",
    "# Draw the tracks for each unique track ID\n",
    "  # ind = index of current iteration\n",
    "    # required an index (enumerate) such that each loop through, for each distinct track, will be assigned a new color \n",
    "  # track = each unique track e.g. track 9 \n",
    "for ind, track in enumerate(df['track'].unique()):\n",
    "    \n",
    "    \n",
    "    track_df = df[df['track'] == track]\n",
    "\n",
    "    # Loop through the color palette and assign the track a new color \n",
    "    color = colors[ind]\n",
    "\n",
    "    # Iterate through the track data and draw lines between consecutive points\n",
    "       # the use of range(len()) will create a sequence of numbers - how to loop over the index \n",
    "       # the for loop will run from the second element (index 1) to the last element in the dataframe\n",
    "       # the reason for starting at index 1 is lines will be drawn by comparing the coordinate with its predecessor to draw a line between them\n",
    "    for i in range(1, len(track_df)):\n",
    "        \n",
    "        # Get the previous and current frame data\n",
    "          # define the current and previous index \n",
    "          # will be used to compare the two rows and draw appropriate lines \n",
    "          # iloc = integer index-based -  have to specify rows and columns by their integer index (loc = specify name)\n",
    "        prev_frame = track_df.iloc[i-1]\n",
    "        curr_frame = track_df.iloc[i]\n",
    "\n",
    "        # Check if the current or previous frame contains NaN in any of the required columns\n",
    "        if not prev_frame[['head.x', 'head.y', 'body.x', 'body.y', 'tail.x', 'tail.y']].isna().any() and not curr_frame[['head.x', 'head.y', 'body.x', 'body.y', 'tail.x', 'tail.y']].isna().any():\n",
    "            \n",
    "            # Draw lines between the corresponding head, body, and tail points\n",
    "              # must be an integer for cv2\n",
    "              #Â cv2.line(img, pt1, pt2, color, thickness=None, lineType=None, shift=None)\n",
    "            cv2.line(tracks_image, \n",
    "                     (int(prev_frame['head.x']), int(prev_frame['head.y'])), \n",
    "                     (int(curr_frame['head.x']), int(curr_frame['head.y'])), \n",
    "                     color=color, \n",
    "                     thickness=1)\n",
    "            cv2.line(tracks_image, \n",
    "                     (int(prev_frame['body.x']), int(prev_frame['body.y'])), \n",
    "                     (int(curr_frame['body.x']), int(curr_frame['body.y'])), \n",
    "                     color=color, \n",
    "                     thickness=1)\n",
    "            cv2.line(tracks_image, \n",
    "                     (int(prev_frame['tail.x']), int(prev_frame['tail.y'])), \n",
    "                     (int(curr_frame['tail.x']), int(curr_frame['tail.y'])), \n",
    "                     color=color, \n",
    "                     thickness=1)\n",
    "\n",
    "# Save the image\n",
    "cv2.imwrite('/Users/cochral/repos/behavioural-analysis/plots/attraction-rig/new.png', tracks_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MB JUST BODY IS BETTER?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the image size\n",
    "image_size = 1400\n",
    "# np.zeros creates a new array filled with zeros\n",
    "# creates a 1400x1400 pixel image with 3 color channels (RGB)\n",
    "tracks_image = np.zeros((image_size, image_size, 3), dtype=np.uint8)\n",
    "\n",
    "# ensure sorted by frame index\n",
    "df = df.sort_values('frame_idx')\n",
    "\n",
    "# Define a list of 10 colors for the tracks\n",
    "colors = [\n",
    "    (255, 0, 0), (0, 255, 0), (0, 0, 255),\n",
    "    (255, 255, 0), (255, 0, 255), (0, 255, 255),\n",
    "    (125, 125, 255), (255, 125, 125), (125, 255, 125),\n",
    "    (50, 100, 150)\n",
    "]\n",
    "\n",
    "# Draw the tracks for each unique track ID\n",
    "  # ind = index of current iteration\n",
    "    # required an index (enumerate) such that each loop through, for each distinct track, will be assigned a new color \n",
    "  # track = each unique track e.g. track 9 \n",
    "for ind, track in enumerate(df['track'].unique()):\n",
    "    \n",
    "    \n",
    "    track_df = df[df['track'] == track]\n",
    "\n",
    "    # Loop through the color palette and assign the track a new color \n",
    "    color = colors[ind]\n",
    "\n",
    "    # Iterate through the track data and draw lines between consecutive points\n",
    "       # the use of range(len()) will create a sequence of numbers - how to loop over the index \n",
    "       # the for loop will run from the second element (index 1) to the last element in the dataframe\n",
    "       # the reason for starting at index 1 is lines will be drawn by comparing the coordinate with its predecessor to draw a line between them\n",
    "    for i in range(1, len(track_df)):\n",
    "        \n",
    "        # Get the previous and current frame data\n",
    "          # define the current and previous index \n",
    "          # will be used to compare the two rows and draw appropriate lines \n",
    "          # iloc = integer index-based -  have to specify rows and columns by their integer index (loc = specify name)\n",
    "        prev_frame = track_df.iloc[i-1]\n",
    "        curr_frame = track_df.iloc[i]\n",
    "\n",
    "        # Check if the current or previous frame contains NaN in any of the required columns\n",
    "        if not prev_frame[['body.x', 'body.y']].isna().any() and not curr_frame[['head.x', 'head.y', 'body.x', 'body.y', 'tail.x', 'tail.y']].isna().any():\n",
    "            \n",
    "            # Draw lines between the corresponding head, body, and tail points\n",
    "              # must be an integer for cv2\n",
    "              #Â cv2.line(img, pt1, pt2, color, thickness=None, lineType=None, shift=None)\n",
    "           \n",
    "            cv2.line(tracks_image, \n",
    "                     (int(prev_frame['body.x']), int(prev_frame['body.y'])), \n",
    "                     (int(curr_frame['body.x']), int(curr_frame['body.y'])), \n",
    "                     color=color, \n",
    "                     thickness=1)\n",
    "          \n",
    "          \n",
    "\n",
    "# Save the image\n",
    "cv2.imwrite('/Users/cochral/repos/behavioural-analysis/plots/attraction-rig/BODY.png', tracks_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next to iterare over all the files in one folder and produce an image like this!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VIDEO OF TRACKS  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the image size\n",
    "image_size = 1400\n",
    "\n",
    "# Define the codec and create VideoWriter object\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Codec used to compress the frames\n",
    "video_output = cv2.VideoWriter('/Users/cochral/repos/behavioural-analysis/plots/attraction-rig/output_video.mp4', fourcc, 10.0, (image_size, image_size))\n",
    "\n",
    "df = df.sort_values('frame_idx')\n",
    "\n",
    "colors = [\n",
    "    (255, 0, 0), (0, 255, 0), (0, 0, 255),\n",
    "    (255, 255, 0), (255, 0, 255), (0, 255, 255),\n",
    "    (125, 125, 255), (255, 125, 125), (125, 255, 125),\n",
    "    (50, 100, 150)\n",
    "]\n",
    "\n",
    "# Initialize a blank image\n",
    "frame_image = np.zeros((image_size, image_size, 3), dtype=np.uint8)\n",
    "\n",
    "# Iterate through each frame index in the DataFrame\n",
    "for frame in range(df['frame_idx'].min(), df['frame_idx'].max() + 1):\n",
    "    frame_df = df[df['frame_idx'] == frame]\n",
    "\n",
    "    track_colors = {track: colors[ind % len(colors)] for ind, track in enumerate(df['track'].unique())}\n",
    "\n",
    "\n",
    "    for track in df['track'].unique():\n",
    "        \n",
    "        track_df = frame_df[frame_df['track'] == track]\n",
    "\n",
    "\n",
    "        color = track_colors[track]\n",
    "\n",
    "        # Ensures there is data for the track in the current frame\n",
    "\n",
    "        for i in range(len(track_df) - 1):\n",
    "\n",
    "            curr_frame = track_df.iloc[i]\n",
    "            next_frame = track_df.iloc[i + 1]\n",
    "\n",
    "            if not any(pd.isna([curr_frame['head.x'], curr_frame['head.y'], next_frame['head.x'], next_frame['head.y'],\n",
    "            curr_frame['body.x'], curr_frame['body.y'], next_frame['body.x'], next_frame['body.y'], \n",
    "            curr_frame['tail.x'], curr_frame['tail.y'], next_frame['tail.x'], next_frame['tail.y']])):\n",
    "                    \n",
    "                    # Draw the line for the current segment\n",
    "                    cv2.line(frame_image, \n",
    "                             (int(curr_frame['head.x']), int(curr_frame['head.y'])), \n",
    "                             (int(next_frame['head.x']), int(next_frame['head.y'])), \n",
    "                             color=color, \n",
    "                             thickness=1)\n",
    "                    cv2.line(frame_image,\n",
    "                     (int(curr_frame['body.x']), int(curr_frame['body.y'])),\n",
    "                     (int(next_frame['body.x']), int(next_frame['body.y'])),\n",
    "                     color=color,\n",
    "                     thickness=1)\n",
    "                    \n",
    "                    cv2.line(frame_image,\n",
    "                     (int(curr_frame['tail.x']), int(curr_frame['tail.y'])),\n",
    "                     (int(next_frame['tail.x']), int(next_frame['tail.y'])),\n",
    "                     color=color,\n",
    "                     thickness=1)\n",
    "                    \n",
    "        \n",
    "\n",
    "    # Write the frame to the video\n",
    "    video_output.write(frame_image)\n",
    "\n",
    "    # Optionally, you can fade lines over time by slightly darkening the frame\n",
    "    frame_image = (0.99 * frame_image).astype(np.uint8)\n",
    "\n",
    "video_output.release()\n",
    "\n",
    "# video output is just black "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "THE BELOW SCRIPT WORKS: CHAT GPT DID THIS ONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the image size\n",
    "image_size = 1400\n",
    "\n",
    "# Define the codec and create VideoWriter object\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Codec used to compress the frames\n",
    "video_output = cv2.VideoWriter('/Users/cochral/repos/behavioural-analysis/plots/attraction-rig/output_video_test.mp4', fourcc, 10.0, (image_size, image_size))\n",
    "\n",
    "df = df.sort_values('frame_idx')\n",
    "\n",
    "colors = [\n",
    "    (255, 0, 0), (0, 255, 0), (0, 0, 255),\n",
    "    (255, 255, 0), (255, 0, 255), (0, 255, 255),\n",
    "    (125, 125, 255), (255, 125, 125), (125, 255, 125),\n",
    "    (50, 100, 150)\n",
    "]\n",
    "\n",
    "\n",
    "# Dictionary to store the last index in DataFrame of each track\n",
    "\n",
    "last_index = {}\n",
    "\n",
    "# Iterate over each frame\n",
    "for frame in range(df['frame_idx'].min(), df['frame_idx'].max() + 1):\n",
    "\n",
    "    # ensure the frame is correct \n",
    "    frame_df = df[df['frame_idx'] == frame]\n",
    "\n",
    "    #  Maps each unique track to a specific color\n",
    "       #Â This ensures that each track uses the same color throughout all frames\n",
    "    track_colors = {track: colors[ind % len(colors)] for ind, track in enumerate(df['track'].unique())}\n",
    "\n",
    "    # Initialize a blank image for this frame\n",
    "      # each frame has its own image - joined up at the end \n",
    "    frame_image = np.zeros((image_size, image_size, 3), dtype=np.uint8)\n",
    "\n",
    "    for track in frame_df['track'].unique():\n",
    "        track_df = frame_df[frame_df['track'] == track]\n",
    "\n",
    "        # if a track has missing data the script will simply just not draw lines\n",
    "        if track_df.empty:\n",
    "            continue\n",
    "\n",
    "        current_index = track_df.index[0]  # Assuming track_df is not empty and has one row\n",
    "\n",
    "\n",
    "        # If the track was previously seen and thus has an entry in last_index, the script fetches the \n",
    "        #Â last known data for this track to draw a line to the current position\n",
    "\n",
    "        if track in last_index:\n",
    "            # Retrieve the previous frame's data using the stored last index\n",
    "            prev_index = last_index[track]\n",
    "            prev_track_df = df.loc[prev_index]\n",
    "\n",
    "            for part in ['head', 'body', 'tail']:\n",
    "                # Extract previous and current coordinates\n",
    "                prev_x = prev_track_df[f'{part}.x']\n",
    "                prev_y = prev_track_df[f'{part}.y']\n",
    "                curr_x = track_df[f'{part}.x'].values[0]\n",
    "                curr_y = track_df[f'{part}.y'].values[0]\n",
    "\n",
    "                # Check if any of the coordinates are NaN before drawing\n",
    "                if not np.isnan([prev_x, prev_y, curr_x, curr_y]).any():\n",
    "                    # Convert to integers\n",
    "                    prev_x, prev_y, curr_x, curr_y = map(int, [prev_x, prev_y, curr_x, curr_y])\n",
    "                    # Draw the line with the corresponding track color\n",
    "                    cv2.line(frame_image, (prev_x, prev_y), (curr_x, curr_y),\n",
    "                             color=track_colors[track], thickness=4)\n",
    "\n",
    "        # Update the last index for this track\n",
    "        last_index[track] = current_index\n",
    "\n",
    "    # Write the frame to the video output\n",
    "    video_output.write(frame_image)\n",
    "\n",
    "# Release the video writer\n",
    "video_output.release()\n",
    "\n",
    "# this works \n",
    "# but the line joins on from the last known position (if breaks in tracks connect to last known position)- this is unwanted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accounts for breaks in the tracks \n",
    "\n",
    "# Set the image size\n",
    "image_size = 1400\n",
    "\n",
    "# Define the codec and create VideoWriter object\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Codec used to compress the frames\n",
    "video_output = cv2.VideoWriter('/Users/cochral/repos/behavioural-analysis/plots/attraction-rig/output_video_test.mp4', fourcc, 10.0, (image_size, image_size))\n",
    "\n",
    "df = df.sort_values('frame_idx')\n",
    "\n",
    "colors = [\n",
    "    (255, 0, 0), (0, 255, 0), (0, 0, 255),\n",
    "    (255, 255, 0), (255, 0, 255), (0, 255, 255),\n",
    "    (125, 125, 255), (255, 125, 125), (125, 255, 125),\n",
    "    (50, 100, 150)\n",
    "]\n",
    "\n",
    "# Dictionary to store the last index of each track\n",
    "last_index = {}\n",
    "# Dictionary to maintain color assignment for each track\n",
    "track_colors = {}\n",
    "\n",
    "# Iterate over each frame\n",
    "for frame in range(df['frame_idx'].min(), df['frame_idx'].max() + 1):\n",
    "    frame_df = df[df['frame_idx'] == frame]\n",
    "\n",
    "    # Initialize a blank image for this frame\n",
    "    frame_image = np.zeros((image_size, image_size, 3), dtype=np.uint8)\n",
    "\n",
    "    # Determine which tracks are currently active\n",
    "    current_tracks = set(frame_df['track'].unique())\n",
    "\n",
    "    # Identify tracks that have disappeared\n",
    "    disappeared_tracks = set(last_index.keys()) - current_tracks\n",
    "    for track in disappeared_tracks:\n",
    "        del last_index[track]  # Remove disappeared tracks from last_index\n",
    "\n",
    "    # Update the track_colors dictionary for any new tracks\n",
    "    for track in current_tracks:\n",
    "        if track not in track_colors:\n",
    "            track_colors[track] = colors[len(track_colors) % len(colors)]\n",
    "\n",
    "    for track in current_tracks:\n",
    "        track_df = frame_df[frame_df['track'] == track]\n",
    "        if track_df.empty:\n",
    "            continue\n",
    "\n",
    "        current_index = track_df.index[0]\n",
    "\n",
    "        if track in last_index:\n",
    "            # Retrieve the previous frame's data using the stored last index\n",
    "            prev_index = last_index[track]\n",
    "            prev_track_df = df.loc[prev_index]\n",
    "\n",
    "            for part in ['head', 'body', 'tail']:\n",
    "                prev_x = prev_track_df[f'{part}.x']\n",
    "                prev_y = prev_track_df[f'{part}.y']\n",
    "                curr_x = track_df[f'{part}.x'].values[0]\n",
    "                curr_y = track_df[f'{part}.y'].values[0]\n",
    "\n",
    "                # Check if any of the coordinates are NaN before drawing\n",
    "                if not np.isnan([prev_x, prev_y, curr_x, curr_y]).any():\n",
    "                    # Convert to integers\n",
    "                    prev_x, prev_y, curr_x, curr_y = map(int, [prev_x, prev_y, curr_x, curr_y])\n",
    "                    # Draw the line with the corresponding track color\n",
    "                    cv2.line(frame_image, (prev_x, prev_y), (curr_x, curr_y),\n",
    "                             color=track_colors[track], thickness=4)\n",
    "\n",
    "        # Update the last index for this track\n",
    "        last_index[track] = current_index\n",
    "\n",
    "    # Write the frame to the video output\n",
    "    video_output.write(frame_image)\n",
    "\n",
    "# Release the video writer\n",
    "video_output.release()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRACK TAILS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accounts for breaks in the tracks \n",
    "\n",
    "# Set the image size\n",
    "image_size = 1400\n",
    "\n",
    "# Define the codec and create VideoWriter object\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Codec used to compress the frames\n",
    "video_output = cv2.VideoWriter('/Users/cochral/repos/behavioural-analysis/plots/attraction-rig/output_video_test_FOLLOW.mp4', fourcc, 10.0, (image_size, image_size))\n",
    "\n",
    "df = df.sort_values('frame_idx')\n",
    "\n",
    "colors = [\n",
    "    (255, 0, 0), (0, 255, 0), (0, 0, 255),\n",
    "    (255, 255, 0), (255, 0, 255), (0, 255, 255),\n",
    "    (125, 125, 255), (255, 125, 125), (125, 255, 125),\n",
    "    (50, 100, 150)\n",
    "]\n",
    "\n",
    "# Dictionary to store the last index of each track\n",
    "last_index = {}\n",
    "# Dictionary to maintain color assignment for each track\n",
    "track_colors = {}\n",
    "\n",
    "# Initialize a background image to accumulate the trails\n",
    "# background_image = np.zeros((image_size, image_size, 3), dtype=np.uint8)\n",
    "\n",
    "# [Initialize variables, VideoWriter, color assignments, etc., as you have done before...]\n",
    "\n",
    "# Create a persistent image to accumulate the trails\n",
    "path_image = np.zeros((image_size, image_size, 3), dtype=np.uint8)\n",
    "\n",
    "# Iterate over each frame\n",
    "for frame in range(df['frame_idx'].min(), df['frame_idx'].max() + 1):\n",
    "    frame_df = df[df['frame_idx'] == frame]\n",
    "    frame_image = np.zeros((image_size, image_size, 3), dtype=np.uint8)  # Start with a fresh frame image\n",
    "\n",
    "    # [Determine current tracks, handle disappeared tracks, update color assignments...]\n",
    "\n",
    "    for track in current_tracks:\n",
    "        track_df = frame_df[frame_df['track'] == track]\n",
    "        if track_df.empty:\n",
    "            continue\n",
    "\n",
    "        current_index = track_df.index[0]\n",
    "\n",
    "        current_tracks = set(frame_df['track'].unique())\n",
    "\n",
    "        for track in current_tracks:\n",
    "            \n",
    "            if track not in track_colors:\n",
    "                \n",
    "                \n",
    "                track_colors[track] = colors[len(track_colors) % len(colors)]\n",
    "\n",
    "\n",
    "\n",
    "        if track in last_index:\n",
    "            prev_index = last_index[track]\n",
    "            prev_track_df = df.loc[prev_index]\n",
    "\n",
    "            for part in ['head', 'body', 'tail']:\n",
    "                prev_x = prev_track_df[f'{part}.x']\n",
    "                prev_y = prev_track_df[f'{part}.y']\n",
    "                curr_x = track_df[f'{part}.x'].values[0]\n",
    "                curr_y = track_df[f'{part}.y'].values[0]\n",
    "\n",
    "                if not np.isnan([prev_x, prev_y, curr_x, curr_y]).any():\n",
    "                    prev_x, prev_y, curr_x, curr_y = map(int, [prev_x, prev_y, curr_x, curr_y])\n",
    "                    cv2.line(path_image, (prev_x, prev_y), (curr_x, curr_y), color=track_colors[track], thickness=4)\n",
    "\n",
    "        last_index[track] = current_index\n",
    "\n",
    "    # Combine the path image and the current frame\n",
    "    combined_image = cv2.addWeighted(path_image, 1.0, frame_image, 1.0, 0)\n",
    "\n",
    "    # Write the combined image to the video output\n",
    "    video_output.write(combined_image)\n",
    "\n",
    "video_output.release()  # Release the video writer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.9.0) :-1: error: (-5:Bad argument) in function 'addWeighted'\n> Overload resolution failed:\n>  - src2 is not a numpy array, neither a scalar\n>  - Expected Ptr<cv::UMat> for argument 'src2'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 62\u001b[0m\n\u001b[1;32m     59\u001b[0m     last_index[track] \u001b[38;5;241m=\u001b[39m current_index\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m# Now combine the path image and the current frame\u001b[39;00m\n\u001b[0;32m---> 62\u001b[0m frame_image \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maddWeighted\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_image\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# Write the combined image to the video output\u001b[39;00m\n\u001b[1;32m     65\u001b[0m video_output\u001b[38;5;241m.\u001b[39mwrite(frame_image)\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.9.0) :-1: error: (-5:Bad argument) in function 'addWeighted'\n> Overload resolution failed:\n>  - src2 is not a numpy array, neither a scalar\n>  - Expected Ptr<cv::UMat> for argument 'src2'\n"
     ]
    }
   ],
   "source": [
    "image_size = 1400\n",
    "\n",
    "# Define the codec and create VideoWriter object\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Codec used to compress the frames\n",
    "video_output = cv2.VideoWriter('/Users/cochral/repos/behavioural-analysis/plots/attraction-rig/output_video_test_FOLLOW.mp4', fourcc, 10.0, (image_size, image_size))\n",
    "\n",
    "df = df.sort_values('frame_idx')\n",
    "\n",
    "colors = [\n",
    "    (255, 0, 0), (0, 255, 0), (0, 0, 255),\n",
    "    (255, 255, 0), (255, 0, 255), (0, 255, 255),\n",
    "    (125, 125, 255), (255, 125, 125), (125, 255, 125),\n",
    "    (50, 100, 150)\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "# Initialize a blank image to start with before the loop\n",
    "# This will serve as the canvas where all tracks will be drawn across frames\n",
    "path_image = np.zeros((image_size, image_size, 3), dtype=np.uint8)\n",
    "\n",
    "# Iterate over each frame\n",
    "for frame in range(df['frame_idx'].min(), df['frame_idx'].max() + 1):\n",
    "    frame_df = df[df['frame_idx'] == frame]\n",
    "\n",
    "    # Determine which tracks are currently active\n",
    "    current_tracks = set(frame_df['track'].unique())\n",
    "\n",
    "    # Update the track_colors dictionary for any new tracks\n",
    "    for track in current_tracks:\n",
    "        if track not in track_colors:\n",
    "            track_colors[track] = colors[len(track_colors) % len(colors)]\n",
    "\n",
    "    for track in current_tracks:\n",
    "        track_df = frame_df[frame_df['track'] == track]\n",
    "        if track_df.empty:\n",
    "            continue\n",
    "\n",
    "        current_index = track_df.index[0]\n",
    "\n",
    "        if track in last_index:\n",
    "            # Retrieve the previous frame's data using the stored last index\n",
    "            prev_index = last_index[track]\n",
    "            prev_track_df = df.loc[prev_index]\n",
    "\n",
    "            prev_x = prev_track_df['head.x']\n",
    "            prev_y = prev_track_df['head.y']\n",
    "            curr_x = track_df['head.x'].values[0]\n",
    "            curr_y = track_df['head.y'].values[0]\n",
    "\n",
    "            # Draw the line for the current segment if the coordinates are valid\n",
    "            if not np.isnan([prev_x, prev_y, curr_x, curr_y]).any():\n",
    "                # Convert to integers\n",
    "                prev_x, prev_y, curr_x, curr_y = map(int, [prev_x, prev_y, curr_x, curr_y])\n",
    "                # Draw the line with the corresponding track color on the path image\n",
    "                cv2.line(path_image, (prev_x, prev_y), (curr_x, curr_y), color=track_colors[track], thickness=2)\n",
    "\n",
    "        # Update the last index for this track\n",
    "        last_index[track] = current_index\n",
    "\n",
    "    # Now combine the path image and the current frame\n",
    "    frame_image = cv2.addWeighted(path_image, 1.0, frame_df, 1.0, 0)\n",
    "\n",
    "    # Write the combined image to the video output\n",
    "    video_output.write(frame_image)\n",
    "\n",
    "# Release the video writer\n",
    "video_output.release()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OVERLAY ONTO THE VIDEO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "maggots",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
